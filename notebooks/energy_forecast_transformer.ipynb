{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e04b680",
   "metadata": {},
   "source": [
    "# Energy Consumption Forecasting with Transformers\n",
    "\n",
    "A workflow for forecasting household energy consumption using a Transformer-based model is presented. The process includes data acquisition, preprocessing, modeling, evaluation, and discussion of results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90f7267",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. Download dataset\n",
    "2. Preprocessing\n",
    "3. Modeling\n",
    "4. Evaluation\n",
    "5. Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5268d000",
   "metadata": {},
   "source": [
    "## 1. Download dataset\n",
    "\n",
    "The dataset is downloaded from the UCI Machine Learning Repository using a dedicated Python module. The file is stored locally if it does not already exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411a27f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from energy_forecast_transformer.download import download_kaggle_dataset\n",
    "# download_kaggle_dataset('uciml/electric-power-consumption-data-set', './data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6255ea70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing import load_and_clean_data\n",
    "\n",
    "df = load_and_clean_data('./data/household_power_consumption.txt')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753550ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from summarytools import dfSummary # for summary of the data\n",
    "dfSummary(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8500b4ff",
   "metadata": {},
   "source": [
    "## 2. Preprocessing\n",
    "\n",
    "In this section, we clean the data, handle missing values, resample the time series, and normalize the features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e146d7",
   "metadata": {},
   "source": [
    "### 2.1 Fill in missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47abd4e",
   "metadata": {},
   "source": [
    "Filling missing values is crucial for time series forecasting. Here, we use linear interpolation to estimate and fill missing data points, ensuring continuity and reducing the risk of bias in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926e8969",
   "metadata": {},
   "outputs": [],
   "source": [
    "from energy_forecast_transformer.preprocessing import fill_missing_values\n",
    "\n",
    "df = fill_missing_values(df)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e69869",
   "metadata": {},
   "source": [
    "### 2.2 Resample dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff479ba9",
   "metadata": {},
   "source": [
    "Resampling the dataset allows to aggregate the data to a different time frequency (e.g., daily). This can help reduce noise and align the data with the requirements of the forecasting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d040147",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing import resample_data\n",
    "\n",
    "df_daily = resample_data(df, freq='D')\n",
    "df_daily.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4897c756",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7cbb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_, axs = plt.subplots(2, 1, figsize=(12, 8), sharex=False)\n",
    "tags = df.columns.tolist()\n",
    "tag = tags[0]\n",
    "\n",
    "# Plot for df (original, minute-level)\n",
    "axs[0].plot(df.index, df[tag], label=tag)\n",
    "axs[0].set_title(f'{tag} (Original Data)')\n",
    "axs[0].set_xlabel('Datetime')\n",
    "axs[0].set_ylabel('Value')\n",
    "axs[0].legend()\n",
    "\n",
    "# Plot for df_daily (resampled, daily)\n",
    "axs[1].plot(df_daily.index, df_daily[tag], label=f'{tag} (Daily)')\n",
    "axs[1].set_title(f'{tag} (Daily Resampled)')\n",
    "axs[1].set_xlabel('Datetime')\n",
    "axs[1].set_ylabel('Normalized Value')\n",
    "axs[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b838be",
   "metadata": {},
   "source": [
    "### 2.3 Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3865d0a5",
   "metadata": {},
   "source": [
    "Normalization scales all features to a common range, typically [0, 1]. This step is important, as it helps the model converge faster and prevents features with larger scales from dominating the learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ae4f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing import normalize_data\n",
    "\n",
    "columns = ['Global_active_power', 'Global_reactive_power', 'Voltage', 'Global_intensity', 'Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3']\n",
    "df_daily, scaler = normalize_data(df_daily, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c629ae7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506f3275",
   "metadata": {},
   "source": [
    "### 2.4 Set up dataset dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dff0b5",
   "metadata": {},
   "source": [
    "We organize the data into dictionaries for training, validation, and testing. Each dictionary contains the time series data, static features, and item identifiers, making it compatible with the modeling framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411faff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = \"1D\"\n",
    "prediction_length = 28 # 4 weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b93cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total = len(df_daily)\n",
    "n_train = int(n_total - prediction_length*2)\n",
    "n_val = int(n_total - prediction_length)\n",
    "n_test = int(n_total)\n",
    "print(f\"Total samples: {n_total}, Train samples: {n_train}, Validation samples: {n_val}, Test samples: {n_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ef8705",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing import create_dataset_dict, transform_start_field\n",
    "from datasets import Dataset, DatasetDict\n",
    "from functools import partial\n",
    "\n",
    "data_train, data_val, data_test = create_dataset_dict(df_daily, n_train, n_val, n_test, prediction_length)\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    'train': Dataset.from_dict(data_train),\n",
    "    'validation': Dataset.from_dict(data_val),\n",
    "    'test': Dataset.from_dict(data_test)\n",
    "})\n",
    "\n",
    "train_dataset = dataset[\"train\"]\n",
    "test_dataset = dataset[\"test\"]\n",
    "\n",
    "train_dataset.set_transform(partial(transform_start_field, freq=freq))\n",
    "test_dataset.set_transform(partial(transform_start_field, freq=freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe30939",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c306c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the structure of the dataset\n",
    "print(dataset[\"train\"][0]['start'])\n",
    "print(len(dataset[\"train\"][0]['target']))\n",
    "print(dataset[\"train\"][6]['feat_static_cat'])\n",
    "print(dataset[\"train\"][0]['feat_dynamic_real'])\n",
    "print(dataset[\"train\"][6]['item_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32150be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_example = dataset[\"train\"][0]\n",
    "validation_example = dataset[\"validation\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd7d9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if prediction_length is correctly set\n",
    "assert len(train_example[\"target\"]) + prediction_length == len(dataset[\"validation\"][0][\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e06ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_samples = 6 * prediction_length\n",
    "\n",
    "figure, axes = plt.subplots()\n",
    "axes.plot(train_example[\"target\"][-num_of_samples:], color=\"blue\")\n",
    "axes.plot(\n",
    "    validation_example[\"target\"][-num_of_samples - prediction_length :],\n",
    "    color=\"red\",\n",
    "    alpha=0.5,\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9ec1e1",
   "metadata": {},
   "source": [
    "### 2.5 Splitting dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2f7b18",
   "metadata": {},
   "source": [
    "Splitting the dataset into training, validation, and test sets allows us to train the model, tune hyperparameters, and evaluate performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d00c6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset[\"train\"]\n",
    "test_dataset = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9873e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the start field to pandas Period\n",
    "\n",
    "from functools import lru_cache\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "@lru_cache(10_000)\n",
    "def convert_to_pandas_period(date, freq):\n",
    "    return pd.Period(date, freq)\n",
    "\n",
    "\n",
    "def transform_start_field(batch, freq):\n",
    "    batch[\"start\"] = [convert_to_pandas_period(date, freq) for date in batch[\"start\"]]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346aa95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "train_dataset.set_transform(partial(transform_start_field, freq=freq))\n",
    "test_dataset.set_transform(partial(transform_start_field, freq=freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349fbc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0][\"start\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817b78e5",
   "metadata": {},
   "source": [
    "### 2.6 Create rolling windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788d9bfa",
   "metadata": {},
   "source": [
    "Rolling windows are used to create overlapping sequences for training and testing. This approach helps the model learn from multiple segments of the time series and improves its ability to forecast future values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ce7c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.dataset.multivariate_grouper import MultivariateGrouper\n",
    "\n",
    "num_of_variates = len(train_dataset)\n",
    "\n",
    "train_grouper = MultivariateGrouper(max_target_dim=num_of_variates)\n",
    "test_grouper = MultivariateGrouper(\n",
    "    max_target_dim=num_of_variates,\n",
    "    num_test_dates=len(test_dataset) // num_of_variates, # number of rolling test windows\n",
    ")\n",
    "\n",
    "multi_variate_train_dataset = train_grouper(train_dataset)\n",
    "multi_variate_test_dataset = test_grouper(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0484d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_variate_train_example = multi_variate_train_dataset[0]\n",
    "multi_variate_test_example = multi_variate_test_dataset[0]\n",
    "print(\"multi_variate_train_example['target'].shape =\", multi_variate_train_example[\"target\"].shape)\n",
    "print(\"multi_variate_test_example['target'].shape =\", multi_variate_test_example[\"target\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2bc8c3",
   "metadata": {},
   "source": [
    "## 3. Modeling\n",
    "\n",
    "In this section, we define and configure the Transformer-based model for time series forecasting. The model is set up to handle multivariate time series data and is tailored to the characteristics of the energy consumption dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee978ad",
   "metadata": {},
   "source": [
    "### 3.1 Model config\n",
    "The model configuration specifies the architecture and hyperparameters of the Transformer, such as input size, prediction length, context length, and number of layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8107274b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import get_informer_config\n",
    "from transformers import InformerForPrediction\n",
    "\n",
    "num_of_variates = len(train_dataset)\n",
    "lags_sequence = [1, 2, 7, 14, 28, 56, 112, 224]\n",
    "context_length = prediction_length * 6\n",
    "\n",
    "config = get_informer_config(\n",
    "    num_of_variates=num_of_variates,\n",
    "    prediction_length=prediction_length,\n",
    "    context_length=context_length,\n",
    "    lags_sequence=lags_sequence,\n",
    "    time_features=[\"day_of_week\", \"day_of_month\", \"day_of_year\"]\n",
    ")\n",
    "\n",
    "model = InformerForPrediction(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500aeaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will iterate over the individual time series of our dataset and add/remove fields or features\n",
    "from src.transformer import create_train_dataloader, create_backtest_dataloader\n",
    "\n",
    "train_dataloader = create_train_dataloader(\n",
    "    config=config,\n",
    "    freq=freq,\n",
    "    data=multi_variate_train_dataset,\n",
    "    batch_size=64,\n",
    "    num_batches_per_epoch=100,\n",
    "    num_workers=2,\n",
    ")\n",
    "\n",
    "test_dataloader = create_backtest_dataloader(\n",
    "    config=config,\n",
    "    freq=freq,\n",
    "    data=multi_variate_test_dataset,\n",
    "    batch_size=16,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfd0a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_dataloader))\n",
    "for k, v in batch.items():\n",
    "    print(k, v.shape, v.type())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ce2d1a",
   "metadata": {},
   "source": [
    "### 3.3 Create model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc55702",
   "metadata": {},
   "source": [
    "The model is instantiated and prepared for training. This includes setting up the optimizer and loss function.\n",
    "\n",
    "<!-- The model is now ready for training. We perform a forward pass to ensure the data pipeline and model are working as expected before starting the training loop. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bddc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform forward pass\n",
    "outputs = model(\n",
    "    past_values=batch[\"past_values\"],\n",
    "    past_time_features=batch[\"past_time_features\"],\n",
    "    past_observed_mask=batch[\"past_observed_mask\"],\n",
    "    static_categorical_features=batch[\"static_categorical_features\"]\n",
    "    if config.num_static_categorical_features > 0\n",
    "    else None,\n",
    "    static_real_features=batch[\"static_real_features\"]\n",
    "    if config.num_static_real_features > 0\n",
    "    else None,\n",
    "    future_values=batch[\"future_values\"],\n",
    "    future_time_features=batch[\"future_time_features\"],\n",
    "    future_observed_mask=batch[\"future_observed_mask\"],\n",
    "    output_hidden_states=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2de6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loss:\", outputs.loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f02efe3",
   "metadata": {},
   "source": [
    "## 3.4 Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c901562",
   "metadata": {},
   "source": [
    "The training process involves optimizing the model parameters using the training data. We monitor the training and validation loss to prevent overfitting and apply early stopping if the validation loss does not improve.\n",
    "\n",
    "<!-- \n",
    "The training process is crucial for the model to learn from the data. We use the training data to adjust the model parameters, aiming to minimize the loss function. The loss function measures how well the model's predictions match the actual data. By optimizing the model parameters, we improve the model's performance.\n",
    "\n",
    "To ensure that the model generalizes well to unseen data, we split the data into training and validation sets. The training set is used to train the model, while the validation set is used to evaluate its performance. We monitor the loss on both sets during training.\n",
    "\n",
    "Overfitting occurs when the model learns the training data too well, including its noise and outliers. This results in poor performance on new, unseen data. To prevent overfitting, we use techniques such as early stopping.\n",
    "\n",
    "Early stopping is a form of regularization used to avoid overfitting. It involves monitoring the validation loss during training and stopping the training process if the validation loss does not improve for a certain number of epochs. This way, we can ensure that the model maintains the ability to generalize to new data.\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d380af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import train_model\n",
    "from accelerate import Accelerator\n",
    "\n",
    "epochs = 20\n",
    "loss_history = []\n",
    "val_loss_history = []\n",
    "best_val_loss = float('inf')\n",
    "patience = 5\n",
    "counter = 0\n",
    "\n",
    "accelerator = Accelerator()\n",
    "device = accelerator.device\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "loss_history, val_loss_history = train_model(\n",
    "    model,\n",
    "    train_dataloader,\n",
    "    test_dataloader,\n",
    "    multi_variate_test_dataset,\n",
    "    config,\n",
    "    prediction_length,\n",
    "    epochs=20,\n",
    "    patience=5,\n",
    "    num_batches_per_epoch=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3fa6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view training\n",
    "loss_history = np.array(loss_history).reshape(-1)\n",
    "x = range(loss_history.shape[0])\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(x, loss_history, label=\"train\")\n",
    "plt.title(\"Loss\", fontsize=15)\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"nll\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd07fc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, len(val_loss_history) + 1), val_loss_history, label=\"validation\")\n",
    "plt.title(\"Validation Loss\", fontsize=15)\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"nll\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fbd912",
   "metadata": {},
   "source": [
    "## 4. Evaluation\n",
    "\n",
    "After training, we evaluate the model on the test set. We calculate performance metrics such as Mean Squared Error (MSE) and visualize the predictions against the actual values to assess the model's forecasting ability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533b18b6",
   "metadata": {},
   "source": [
    "### Generating Predictions\n",
    "\n",
    "We use the trained model to generate forecasts for the test set. The predictions are then compared to the actual values to evaluate model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d375dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "forecasts_ = []\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    outputs = model.generate(\n",
    "        static_categorical_features=batch[\"static_categorical_features\"].to(device)\n",
    "        if config.num_static_categorical_features > 0\n",
    "        else None,\n",
    "        static_real_features=batch[\"static_real_features\"].to(device)\n",
    "        if config.num_static_real_features > 0\n",
    "        else None,\n",
    "        past_time_features=batch[\"past_time_features\"].to(device),\n",
    "        past_values=batch[\"past_values\"].to(device),\n",
    "        future_time_features=batch[\"future_time_features\"].to(device),\n",
    "        past_observed_mask=batch[\"past_observed_mask\"].to(device),\n",
    "    )\n",
    "    forecasts_.append(outputs.sequences.cpu().numpy())\n",
    "\n",
    "forecasts = np.vstack(forecasts_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678ae2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluation import compute_mean_mse\n",
    "\n",
    "mse_values, mean_mse = compute_mean_mse(multi_variate_test_dataset, forecasts, prediction_length)\n",
    "for i, mse in enumerate(mse_values):\n",
    "    print(f\"{tags[i]}: MSE = {mse:.4f}\")\n",
    "print(f\"Mean MSE across all variables: {mean_mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c1a79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluation import plot_forecasts\n",
    "from gluonts.dataset.field_names import FieldName\n",
    "\n",
    "plot_forecasts([0,1,2,3,4,5,6], tags, multi_variate_test_dataset, forecasts, prediction_length, FieldName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7398fb2f",
   "metadata": {},
   "source": [
    "## 5. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e08b94c",
   "metadata": {},
   "source": [
    "The Informer-based Transformer model demonstrated strong performance in forecasting daily household energy consumption. The final prediction plots show that the model is able to closely follow the actual values for all variables, with the predicted means and confidence intervals generally capturing the true trends and fluctuations. The Mean Squared Error (MSE) values across all variables are low, indicating accurate predictions. Although the predictions for the submeterings could be better, the model generalizes well and provides reliable forecasts. This approach is effective for multivariate time series forecasting in energy consumption scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01aae403",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv energy-forecast)",
   "language": "python",
   "name": "energy-forecast-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
